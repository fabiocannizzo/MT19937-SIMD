\documentclass[preprint,1p,times]{elsarticle}
%\usepackage{a4wide}
%\usepackage{graphicx}
%\usepackage{amsfonts}
%\usepackage{multirow}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{centernot}
\usepackage{verbatim}
%\usepackage{algorithmicx}
\usepackage{amssymb}
\usepackage{amsmath}
%\usepackage{filecontents}
\usepackage{listings}
%\usepackage[T1]{fontenc}
%\usepackage{float}
%\usepackage[utf8]{inputenc}
%\usepackage[english]{babel}
%\usepackage[margin=0.8in]{geometry}
\usepackage[hidelinks]{hyperref}
\usepackage{pgfplots}
\usepackage{enumitem}
\usepackage{titlesec}
\usetikzlibrary{patterns}

\titleclass{\subsubsubsection}{straight}[\subsection]

\newcounter{subsubsubsection}[subsubsection]
\renewcommand\thesubsubsubsection{\thesubsubsection.\arabic{subsubsubsection}}
\renewcommand\theparagraph{\thesubsubsubsection.\arabic{paragraph}} % optional; useful if paragraphs are to be numbered

\titleformat{\subsubsubsection}
  {\normalfont\normalsize\itshape}{\thesubsubsubsection}{1em}{}
\titlespacing*{\subsubsubsection}
{0pt}{3.25ex plus 1ex minus .2ex}{1.5ex plus .2ex}

\makeatletter
\renewcommand\paragraph{\@startsection{paragraph}{5}{\z@}%
  {3.25ex \@plus1ex \@minus.2ex}%
  {-1em}%
  {\normalfont\normalsize\itshape}}
\renewcommand\subparagraph{\@startsection{subparagraph}{6}{\parindent}%
  {3.25ex \@plus1ex \@minus .2ex}%
  {-1em}%
  {\normalfont\normalsize\itshape}}
\def\toclevel@subsubsubsection{4}
\def\toclevel@paragraph{5}
\def\toclevel@paragraph{6}
\def\l@subsubsubsection{\@dottedtocline{4}{7em}{4em}}
\def\l@paragraph{\@dottedtocline{5}{10em}{5em}}
\def\l@subparagraph{\@dottedtocline{6}{14em}{6em}}
\makeatother

\setcounter{secnumdepth}{4}
\setcounter{tocdepth}{4}


\pgfplotsset{compat=1.9}

\pgfplotsset{
    /pgfplots/ybar legend/.style={
    /pgfplots/legend image code/.code={%
       \draw[##1,/tikz/.cd,yshift=-0.25em]
        (0cm,0cm) rectangle (3pt,0.8em);},
   },
}

\pgfplotsset{every axis/.append style={
		font=\footnotesize,
		line width=0.6pt,
		}}

%\definecolor{electriccyan}{rgb}{0.0, 1.0, 1.0}
%\definecolor{electricgreen}{rgb}{0.0, 1.0, 0.0}
%\definecolor{ao(english)}{rgb}{0.0, 0.5, 0.0}

%\newcommand\bibsection{\section*{\bibname\markright{\MakeUppercase{\bibname}}}}

% \journal{TBD}
% \journal{Journal of Parallel and Distributed Computing}

\begin{document}

\newenvironment{myitemize}
{ \begin{itemize} [topsep= 3pt] %\parskip]
    \setlength{\itemsep}{0pt}
    \setlength{\parskip}{0pt}
    \setlength{\parsep}{0pt}     }
{ \end{itemize}                  }

\newcommand {\inred}[1] {\textcolor{red}{#1}}
\newcommand {\curle}[1]{ \left \{      #1 \right \}      }
%\newcommand\XOR{\mathbin{\char`\^}}
\newcommand\XOR{\mathbin{\oplus}}
\newcommand\OR{\mid}
\newcommand\AND{\&}



\begin{frontmatter}
\title{A SIMD oriented re-engineering of Mersenne twister 19937}

\author{\renewcommand*{\thefootnote}{\fnsymbol{footnote}}
	Fabio Cannizzo\footnote{DISCLAIMER: Although Fabio Cannizzo is employed by Standard Chartered at the time this paper is written, this paper has been produced by Fabio Cannizzo in a personal capacity and Standard Chartered is not associated or responsible for its content in any way.}}

\begin{abstract}
Many modern simulation applications require the generation of long sequences of pseudo-random numbers. 
Linear recurrences modulo 2 are widely used as the basic building block for the construction of pseudo-random numbers generators with very long period and good statistical properties.
These essentially entails of a long binary state vector which evolves iteratively via linear transformations.
A widely accepted pseudo-random generator belonging to this family is the Mersenne twister 19937 (MT19937) proposed by Matsumoto and Nishimura \cite{mt19937}, which is available in several software libraries and numerical packages.
One of the features which determined the MT19937 success is the simplicity of its algorithm. The linear transformation which evolves the binary state vector can be simplified to a very small set of elementary bit manipulations, allowing for a very fast implementation.
Such transformation however is not amenable to take advantage of SIMD\footnote{Single Instructions Multiple Data} instructions available on modern hardware to achieve further speed up.
This paper proposes a technique to re-engineer the MT19937 to to fully exploit SIMD hardware. The idea is to interleave the state vectors of multiple MT19937 generators, evolve their states simultaneously via SIMD operations, then generate random numbers by polling them one by one in round robin fashion. Test results demonstrate that the technique allows to achieve a generator throughput which scales almost linearly with the size of the SIMD register used.
\end{abstract}

\begin{keyword}
pseudo-random \sep Mersenne-Twister \sep SIMD \sep vectorization \sep SSE \sep AVX \sep AVX512
\end{keyword}

\end{frontmatter}

%----------------------------------------------------------------------------------------------------------%
\section{Introduction}
\label{sec:introduction}
Many modern simulation applications require the generation of a large number of pseudo-random numbers. Pseudo-random numbers are not truly random, they are sequences of numbers generated by deterministic algorithms designed to resembles some of the statistical properties of randomness. 

Linear recurrences modulo 2 are widely used as the basic building block for the construction of pseudo-random numbers generators with very long period and good statistical properties.
These essentially entails of a long binary state vector which evolves iteratively via linear transformations.

A widely accepted pseudo-random generator belonging to this family is the Mersenne twister 19937 (MT19937) proposed by Matsumoto and Nishimura \cite{mt19937}. This is now available in several software libraries and numerical packages like Matlab, Octave, NAG, Intel MKL, the C++ Standard Template Library, just to mention a few.

One of the features which determined the MT19937 success is the simplicity of its algorithm. The linear operation which evolves the binary state vector can be simplified to a very small set of elementary bit manipulations, allowing for a very fast implementation.

Such transformation however is not amenable to take advantage of SIMD\footnote{Single Instructions Multiple Data} operations available on modern hardware to achieve further speed up. To obviate this problem, Saito and Matsumoto \cite{sfmt19937} proposed SFMT19937, a specialized version of the MT19937 which target specifically architectures with 128-bits wide registers, like Intel SSE and ARM NEON. While this is an excellent improvement on MT19937, it is not generically adaptable to architectures with other register lengths, e.g. 256-bits (Intel AVX), 512-bits (Intel AVX512) or even wider, as found on GP-GPUs.

This paper proposes a technique to re-engineer the MT19937 to to fully exploit SIMD hardware. The idea is to interleave the state vectors of multiple MT19937 generators, evolve their states simulateneosuly via perfect SIMD operations, then generate random numbers by polling them one by one in round robin fashion.

%----------------------------------------------------------------------------------------------------------%

\subsection{Problem Description}


%----------------------------------------------------------------------------------------------------------%
\subsection{Related Work}
\label{sec:relatedwork}
%----------------------------------------------------------------------------------------------------------%


\subsection{Contribution}

\section{Mersenne twister 19937}
\subsection{Algorithm description}
The MT19937 is a pseudo random number generator due to Matsumoto and Nishimura \cite{mt19937}.
Given an initial state $X$ made of $n$ words of $w$ bits each $X=(x_0, x_1, \dots x_{n-1})$, it generates a sequence $\bold{Z}$ of pseudo random words $z_{0}, z_{1}, \dots, z_{n+P-1}$, with uniform distribution in the range $[0, 2^w-1]$, where $P$ is the period of the generator, after which the sequence of numbers repeats itself. \\

\noindent Pseudo random words $z_k$ ($k=0, \dots, P-1$) are generated sequentially via the following algorithm:
\begin{equation}
\label{eq:formula}
\begin{aligned}
    x_{k+n} &= f(x_{k}, x_{k+1},\dots, x_{k+n-1}) \\
    z_k &= g(x_{k+n}) \\
\end{aligned}
\quad k=0\dots P-1
\end{equation}
\\To describe the transformations $f(\cdot)$ and $g(\cdot)$ used in \eqref{eq:formula}, we first introduce some notation. Let $a$ and $b$ be words of $w$ bits and $\alpha$ be an integer in the range $0\le \alpha \le w$ and $A$ be a binary matrix of size $w \times w$:
\begin{itemize}
%    \item a bold lowercase variable $\textbf{a}$ refers to a $w$-bits word
%    \item $(a^0, a^1, \dots, a^{w-1})$ are the individual bits of the word $\textbf{a}$, where $a^0$ is the lease significant bit
    \item $(a \OR b)$ is the bitwise OR of $a$ and $b$
    \item $(a \XOR b)$ is the bitwise XOR of $a$ and $b$
    \item $(a \AND b)$ is the bitwise AND of $a$ and $b$
    \item $(a \gg \alpha)$ is the bitwise SHIFT RIGHT of $a$ by $s$ positions
    \item $(a \ll \alpha)$ is the bitwise SHIFT LEFT of $a$ by $s$ positions
    \item $(a~\%~b)$ is the remainder of the integer division of $a$ and $b$
    \item $a \star A$ is the binary matrix-matrix product in modulo-2, where $a$ is interpreted as a row binary matrix
\end{itemize}
The recurrence $f(\cdot)$ used in \eqref{eq:formula} to obtain the new element of the state vector is
\begin{equation}
\label{eq:step}
    x_{k+n} = f(x_{k},x_{k+1}, \dots, x_{k+n-1}) = x_{k+m} \XOR \left[ \underbrace{\left(({x_k}~\AND~h) \OR (x_{k+1}~\AND~l)\right) }_u \star A \right]
\end{equation}
where
\begin{itemize}
    \item $h$ and $l$ are $w$-bits constant words defined as $h=\sum_{i=r}^{w-1}2^i$ and $l=\sum_{i=0}^{r-1}2^i$, for some chosen integer $0 \le r \le w-1$ 
    \item $A$ is a constant binary matrix of size $w \times w$
    \item $m$ is an index chosen in the range $0 \le m < n$
    \item $r$ is a separation point in the words in the range $0 \le r \le w-1$
\end{itemize}
The matrix $A$ has a particular structure chosen so that the vector matrix multiplication $(u\star A)$ can be carried out quickly with just a few simple bit manipulations. Let $(a_0, a_1, \dots, a_{w-1})$ the individual bits of some constant word $a$, where $a_0$ is the least significant bit, and $I_{w-1}$ a binary identity matrix of size $(w-1)$
\begin{equation}
A = \left[ \begin{matrix} 0 & I_{w - 1} \\ a_{w-1} & (a_{w - 2}, \ldots , a_0) \end{matrix} \right] \quad \implies \quad u\star A = \begin{cases}u \gg 1 & \text{if $u$ is even}\\(u \gg 1) \oplus a & \text{if $u$ is odd}\end{cases}
\end{equation}
Note that although the stored state vector has size $nw$ bits, the lower $r$ bits of $x_k$ are not used in transformation \eqref{eq:step} and after the transformation is complete they are discarded, so the effective dimension of the state vector is only $nw-r$ bits. \\ % This determines the period of the generator $P=2^{nw-r}-1$.
\\ The transformation $g(\cdot)$, called tempering, is also chosen to be quickly computable. For some chosen value of the $w$-bits constant words $d$, $b$, $c$, and some chosen values of the constants $\alpha$, $\beta$, $\gamma$ and $\delta$ in the range $[0,32]$, $z=g(x)$ is obtained via the sequence of transformations
\begin{equation}
\label{eq:tempering}
\begin{aligned}
y &= x \oplus ((x\gg \alpha)~\And~d)\\
y &= y \oplus ((y\ll \beta)~\And~b)\\
y &= y \oplus ((y\ll \gamma)~\And~c)\\
z &= y \oplus (y\gg \delta)
\end{aligned}
\end{equation}
The chosen value for all the above parameters are:
\begin{equation}
\label{eq:params}
\begin{aligned}
(w, n, m, r) &= (32, 624, 397, 31)\\
a &= \textrm{9908B0DF}\\
(\alpha, d) &= (11, \textrm{FFFFFFFF})\\
(\beta, b) &= (7, \textrm{9D2C5680})\\
(\gamma, c) &= (15, \textrm{EFC60000})\\
\delta &= 18\\
\end{aligned}
\end{equation}
where the words $a$, $d$, $b$ and $c$ are expressed in hexadecimal format. These choice of parameters yield a huge generator period $P=2^{nw-r}-1=2^{19937}-1$ and good K-distribution properties of the generator.

\subsection{Implementation}
For each new random word generated in \eqref{eq:formula} the state vector is transformed by \eqref{eq:step} removing the least significant word $x_{k}$ on its left side and adding a new word $x_{k+n}$ on its right side. Starting with an initial state vector $X_0=(x_0, x_1, \dots, x_{n-1})$, the state vector evolves as
$$
\begin{matrix}
X_0 &=& x_0 & x_1 & \dots & x_{n-1} &\\
X_1 &=& & x_1 & x_2 & \dots & x_{n} & \\
X_2 &=& & & x_2 & \dots & \dots & x_{n+1} &\\
\cdots \\
\end{matrix}
$$
This can be effectively implemented as a circular buffer of size $n$, which avoids shifting the position of each word inside the vector at each iteration.
\begin{equation}
\label{eq:staterec}
\begin{matrix}
X_0 &=& x_0 & x_1 & x_2 & \dots & x_{n-1} \\
X_1 &=& x_{n} & x_1 & x_2 & \dots & x_{n-1} \\
X_2 &=& x_{n} & x_{n+1} & x_2 & \dots & x_{n-1} \\
\cdots \\
\end{matrix}
\end{equation}
Transition \eqref{eq:step} can be rewritten in terms of the circular buffer by taking the modulo-$n$ of all indices.
\begin{equation}
\label{eq:stepmod}
x_{k\%n} = x_{(k+m)\% n} \XOR \left[ \left(({x_{k\%n}}~\AND~h) \OR (x_{(k+1)\%n}~\AND~l)\right) \star A \right]
\end{equation}
Note that after $n$ steps, i.e. repeating \eqref{eq:stepmod} $n$ times, all elements of the state vector are replaced by new ones. To avoid the use of the modulo-$n$ operator on the array indices, the loop which generates an entirely new state vector can be broken in 3 sub-loops, depending on when the 3 indices $k$, $k+1$ and $k+m$ become larger than $n-1$.
\begin{equation}
\label{eq:stepnomod}
\begin{aligned}
x_{k} &= x_{k+m} \XOR \left[ \left((x_{k}~\AND~h) \OR (x_{k+1}~\AND~l)\right) \star A \right] \quad &&k = 0, \dots, n-m-1\\
x_{k} &= x_{k+m-n} \XOR \left[ \left((x_{k}~\AND~h) \OR (x_{k+1}~\AND~l)\right) \star A\right] \quad &&k = n-m, \dots, n-2 \\
x_{k} &= x_{k+m-n} \XOR \left[ \left((x_{k}~\AND~h \OR x_{0}~\AND~l)\right) \star A \right] \quad &&k = n-1
\end{aligned}
\end{equation}
After the state vector has been advanced by $n$ steps, $n$ new pseudo random words can be produced by applying transformation \eqref{eq:tempering} to the new state elements.
\subsection{Vectorization difficulties}
The specific parameters \eqref{eq:params} chosen for the MT19937 are $w=32$, $n=624$, $r=31$ and $m=397$, so in order to generate an entirely new state vector the first instruction in \eqref{eq:stepnomod} needs to be executed 227 times, the second one 396 times and the last one just once. Vectorization consists in packing operations carried out in loops \eqref{eq:stepnomod} so that multiple iterations can be done simultaneously using SIMD instructions. For instance, SSE2 registers are 128 bits wide and allow to pack 4x32-bit words operations into a single operation. The first instruction in \eqref{eq:stepnomod} could be implemented in vectorial format as:
\begin{align}
\label{eq:stepsse2}
\begin{pmatrix}x_{k} \\ x_{k+1} \\ x_{k+2} \\ x_{k+3} \end{pmatrix}
&= \begin{pmatrix}x_{k+m} \\ x_{k+1+m} \\ x_{k+2+m} \\ x_{k+3+m} \end{pmatrix} \XOR \left[ \left(\left(\begin{pmatrix}x_{k} \\ x_{k+1} \\ x_{k+2} \\ x_{k+3} \end{pmatrix}~\AND~h\right) \OR \left(\begin{pmatrix}x_{k+1} \\ x_{k+2} \\ x_{k+3} \\ x_{k+4} \end{pmatrix}~\AND~l\right)\right) \star A \right] \quad && k=0, 4, \dots, 220 \\
\label{eq:stepssescalar}
x_k &= x_{(k+m)} \XOR \left[ \left((x_{k}~\AND~h) \OR (x_{k+1}~\AND~l)\right) \star A \right]\quad &&k = 224, 225, 226
\end{align}
Because 227 is not a perfect multiple of 4, the best which can be done is to carry out 56 iterations in packs of 4 as in \eqref{eq:stepsse2}, then some special handling is needed for the last 3 iterations in \eqref{eq:stepssescalar}. Similar considerations would apply using SIMD registers of different width, e.g. AVX registers, which are 256-bits wide or AVX512 registers which are 512-bits wide.

A second issue is that the tuples $(x_k, x_{k+1}, x_{k+2}, x_{k+2})$ appearing in \eqref{eq:stepsse2} are in general not perfectly aligned in memory. For example, if the tuple $(x_k, x_{k+1}, x_{k+2}, x_{k+3})$ was stored at a memory address which is a perfect multiple of 16 (the size in bytes of an SSE2 register), then the tuple $(x_{k+1}, x_{k+2}, x_{k+3}, x_{k+4})$ would be stored at a memory address incremented by 4 bytes, which cannot be a multiple of 16. Similarly the tuple $(x_{k+m}, x_{k+1+m}, x_{k+2+m}, x_{k+3+m})$ would be stored at a memory address incremented by 397x4 bytes (remember that $m=397$), which also cannot  be a multiple of 16. Because of hardware limitations, the lack of memory alignment causes slow load and save memory operations, at least on x86-64 CPUs (see \cite{intel} sections 6.3, 15.6 and 18.23).

\section{Re-engineering for SIMD}
\label{sec:simdgen}
Given a certain initial state $X_0$, the MT19937 pseudo-random number generator produces a sequence $\bold{Z}$ of independent and uniformly distributed random numbers $z_k$ with a period of $P=2^{19937}-1$.
\begin{equation}
\label{eq:mainseq}
   \bold{Z} = z_0, z_1, \dots, z_{P-1} 
\end{equation}
Let's consider $M$ sub-sequences $\bold{Z_t}$ ($t=0\dots M-1$) of equal size $J$ obtained by partitioning the first $M\cdot J$ numbers of sequence $\bold{Z}$ in groups of equal length $J$
\begin{equation}
\label{eq:subseq}
   \underbrace{z_0, z_1, \dots, z_{J-1}}_{\bold{Z_0}},\, \underbrace{z_J, z_{J+1}, \dots, z_{2J-1}}_{\bold{Z_1}}, \dots,\, \underbrace{z_{(M-1)J}, z_{(M-1)J+1}, \dots, z_{MJ-1}}_{\bold{Z_{M-1}}}
\end{equation}
Let's construct a new sequence $\bold{S}$ which interleaves the sequences $\bold{Z_t}$
\begin{equation}
\label{eq:combseq}
   \bold{S}=\underbrace{z_0, z_J, z_{2J}, \dots, z_{(M-1)J,}}_{\text{1-st number from each sub-sequence}} \,\underbrace{z_1, z_{J+1}, z_{2J+1}, \dots, z_{(M-1)J+1},}_{\text{2-nd number from each sub-sequence}}\, \dots, \underbrace{z_{J-1}, z_{2J-1}, z_{3J-1}, \dots, z_{MJ-1}}_{\text{$J$-th number from each sub-sequence}}
\end{equation}
Note that, because the numbers in the original sequence $\bold{Z}$ are independent, the new sequence $\bold{S}$ obtained by interleaving the sub-sequences $\bold{Z_t}$ is also independent.

Given a CPU architecture with SIMD register size of width $L$ expressed in number of bits, we can choose $M$ as the number of 32-bit words which fits in the SIMD registers, i.e. $M=L/32$. We divide the total periods in sub-sequences of length $$J=\frac{P+1}{M}=2^{19937-\log_2M}$$
For example, working with AVX512 instructions where $L=512$, we have $M=16$, $J=2^{19933}$. Note that, because the total period is $P$ and not $P+1$, we choose the last sequence $S_{M-1}$ to be shorter than the others and have length $J-1$ instead of $J$.

A pseudo-random number generator which produces the sequence $\bold{S}$ can be obtained by duplicating $M$ times the original MT19937 generator with initial state $X_0$, thus obtaining an array of $M$ MT19937 generators $G_t$ ($t=0,\dots, M-1$) with identical state vector $X_0$. Then we advance the state vector of each generator $G_t$ by $(t\cdot J)$ steps, so that it will produce the sequence $\bold{S_t}$. Last we combine the array of generators $G_t$ ($t=0,\dots, M-1$) into a single new generator, which produces a sequence by polling each of the $G_t$ generators in round robin mode, i.e. it produces the desired sequence $\bold{S}$. 

Let's add a second index $t$ to the state vector, so that $X_{k,t}$ is the state $k$-th for the $t$-th generator, i.e. $X_{0,t}=X_{tJ}$, the multi-generator described below has initial state
$$
\begin{pmatrix}
    X_{0,0} \\ X_{0,1} \\ \vdots \\ X_{0,M-1}
\end{pmatrix}
= 
\begin{pmatrix}
    x_{0,0} & x_{1,0} & \cdots & x_{n-1,0} \\
    x_{0,1} & x_{1,1} & \cdots & x_{n-1,1} \\
    \cdots \\
    x_{0,M-1} & x_{1,M-1} & \cdots & x_{n-1,M-1} \\
\end{pmatrix}
$$
By interleaving in memory the words of the state vectors of the $M$ generators, we obtain for the multi-generator a combined state vector $\hat{X}_0$
$$
    \hat{X}_0 = [(x_{0,0}, x_{0,1}, \dots x_{0,M-1}), (x_{1,0}, x_{1,1}, \dots x_{1,M-1}), \dots (x_{n-1,0}, x_{n-1,1}, \dots x_{n-1,M-1})]
$$
This allows to transform each of the 32-bits operations in \eqref{eq:step} into a $L$-bits operation which advances by one step the $M$ state vectors simultaneously, hence reducing computation cost by a factor $M$.

\section{Computation of the state vectors $X_{tJ}$}
To be able to construct the generator described in section \ref{sec:simdgen}, we need to be able to advance the state vector $X_0$ by $J$ steps. In theory, we could apply $J$ times transformation \eqref{eq:setp}. In practice, since $J$ is a huge number, this is an astronomically expensive operation. There are however techniques which allow to compute directly the state $X_{tJ}$ from the state $X_0$ without computing all the intermediate states. This techniques are called \textit{jump ahead}.\\
\\ The simplest \text{jump ahead} methodology for the MT19937 is based on simple matrix multiplications, as proposed by Knuth \cite{knuth}.
Let's $Y$ be a subset of the state vector $X$, where we removed the first $r$ ($r$=31) bits, which are not used in the transformation \eqref{eq:step}. The effective state vector $Y$ is a binary matrix with dimensions $1\times (nw-r)$. Advancing the effective state vector $Y_k$ to $Y_{k+1}$ using \eqref{eq:step} is equivalent to a binary vector-matrix multiplication modulo-2
\begin{equation}
Y_{k+1} = Y_k \star F
\end{equation}
where $F$ is the following square binary matrix of size $wn-r$
\begin{equation}
\label{eq:transmat}
    F = \begin{pmatrix}
        0 & I_w & 0 & \cdots & &  &  &  & 0 \\
        \vdots & 0 & I_w & 0 & \cdots & & & & 0\\
        0 & \vdots & 0 & \ddots & &&& & \vdots \\
        I_w & 0 & \vdots & & \ddots & && & \vdots \\
        0 & \vdots &  & & & \ddots & & & \vdots \\
        \vdots &  &  &  & &&& I_w & 0 \\
        0 &  &  & &  & &&&I_{w - r} \\
        A & 0 & \cdots & &  &  &&& 0
\end{pmatrix}
\begin{matrix}
\\ \\ \\ \leftarrow m\text{-th row} \\ \\ \\ \\
\end{matrix}
\end{equation}
State $X_{tJ}$ can be computed as
\begin{equation}
\label{eq:jumpahead}
    Y_{tJ} = Y_{tJ-1} \star F = Y_{tJ-2}  \star F \star F = \ldots = Y_{(t-1)J}  \star F^{J}, \quad j=1,\dots,M-1
\end{equation}
Let $B=F^J$, since $J$ is a power of 2 ($J=2^{q}$, where $q=19933$)
$$
    B=F^{J}=F^{2^q}=F^{2^{q-1}} \star F^{2^{q-1}}
$$
suggesting the following simple algorithm to compute $B$
$$
    F^{2^q} = F^{2^{q-1}} \star F^{2^{q-1}}, \quad q=1, 2, \dots, 19333
$$
The computation of $B=F^{2^{19933}}$ requires 19933 matrix square operations and takes a few hours using SIMD optimized code on a 32 core machine.
The computation can be done offline and the matrix $B$ can be stored. It requires approximately 47Mb of disk space if stored in binary format. It can be compressed to approximately 296Kb using LZMA2 compression (7z format). The overhead associated with initializing the generator state vectors as in \eqref{eq:jumpahead}, which requires $M$-1 vector-matrix multiplications, is negligible in the context of the generation of a large stream of pseudo random numbers.

It is worth mentioning that there exist more efficient and faster \textit{jump-ahead} algorithms which do not require storage of the jump matrix and are faster then performing a vector-matrix multiplication as in \eqref{eq:jumpahead}. Examples can be found in \cite{jump1} and \cite{jump2}. These have not been considered here as the method discussed above is simpler to implement and it is already quite fast. Furthermore, the contribution of this paper is the parallelization of the algorithm to advance the state vector. If the specific methodology used to perform \textit{jump-ahead} was to be replaced by a more efficient one, that would just be an improvement and it would not invalidate any of the arguments presented in this paper.

\section{Implementation details}
An implementation of this generator is available on github\footnote{https://github.com/fabiocannizzo/MT19937-SIMD}. It uses a few optimization techniques introduced to speed up SIMD computations.
\begin{itemize}
    \item The state vector is memory aligned on a 64 bytes boundary, thus allowing to use SIMD load and store operations without incurring cache split penalties.
    \item One of the elementary operations done when updating the state vector, consists of picking a 32-bit constant or a zero, depending if the value of another 32bit constant is even or odd. Using C++ notation: \\
    \lstinline{unsigned w = y % 2 ? k : 0}. \\
    This is carried out using special SIMD operators and bit masking, to avoid to incur branching penalties. For example, with SSE2 instructions, it becomes: \\
    \lstinline{__m128d w = ((y & 1) > 0) & k}, \\ where $w,\,y,\,k,\,0\, \text{and}\, 1$ are SIMD vectors. This works because the SSE2 SIMD operator '$>$' returns a mask with all bits set to ones or zeros, depending if the comparison is true or false.
    \item In the original Mersenne twister source code\footnote{http://www.math.sci.hiroshima-u.ac.jp/m-mat/MT/MT2002/CODES/mt19937ar.c} the entire state vector of 624 32-bit words is updated in one single loop, i.e. when the 624 words of the state have been consumed, new 624 words are generated and stored in memory by advancing the generator 624 times. Then random numbers are generated by reading successive words from the state vector and tempering them one by one on the fly. Here instead we perform tempering on the $624\times M$ words of the state vector in the same loop where we update it and we store in memory the tempered numbers in a separate vector, so that we can generate them using SIMD instructions.
    \item SIMD constants are defined statically, so that when they are needed they can be simply loaded from memory
\end{itemize}

\section{Test results}
Time in seconds to generate 5 billions uniform discrete 32-bit random numbers.
\begin{center}
\begin{tabular}{|c| c| c| c|c|} 
 \hline
 Implementation & M & CPU-1 & CPU-1 & CPU-3 \\
 \hline
 original C code & 1 & 31.74 & 20.00 & 16.90 \\ 
 \hline
 MT19937SIMD (scalar) & 1 & 19.52 & 12.41 & 16.12 \\
 \hline
 MT19937SIMD (SSE2) & 4 & 10.11 & 5.47 & 6.10 \\
 \hline
 MT19937SIMD (AVX2) & 8 & n.a. & 3.75 & 3.08 \\
 \hline
 MT19937SIMD (AVX512) & 16 & n.a. & n.a. & 2.65 \\
 \hline
\end{tabular}
%\caption{Time in seconds to generate 5 billions uniform discrete 32-bit random numbers.}
\label{tab:results}
\end{center}
The C++ implementation of MT19937SIMD used to produce these test results is available at: \\ https://github.com/fabiocannizzo/MT19937-SIMD \\
The executable have been compiled with g++ 11.3 targeting x86-64 architecture\\
Command line flags: -O3 -std=c++17 -mXXX, where XXX is one of sse4.2, avx2, avx512f, depending on which performance test we want to run. \\
The CPUs referenced in the table have specifications:
\begin{enumerate}
    \item Intel(R) Celeron(R) J4125, cache 4Mb, frequency 2.0 GHz, burst frequency 2.7 GHz, SIMD support for SSE4.2
    \item Intel® Core™ i9-12900H, cache 24Mb cache, base frequency 3.8GHz, turbo frequency 5.0 GHz, SIMD support for AVX2
    \item Intel® Xeon® Gold 6234, cache 24.75Mb, base frequency 3.3GHz, turbo frequency 4.0 GHz, SIMD support for AVX512
\end{enumerate}


%-------------------------------------------BIBLIOGRAPHY-------------------------------------------------------------------------------------
%----------------------------------------------------------------------------------------------------------%
%\begin{comment}
%----------------------------------------------------------------------------------------------------------%
\begin{thebibliography}{9}
\bibitem{ecuyer} 2002, P. L’Ecuyer, R. Simard, E. J. Chen, W. D. Kelton, "An object-oriented random-number package with many long streams
and substreams." Oper. Res. 50 1073–1075.
\bibitem{mt19937} 1998, M. Matsumoto, T. Nishimura, "Mersenne Twister: A 623-dimensionally equidistributed uniform pseudorandom number generator", ACM Trans. on Modeling and Computer Simulation Vol. 8, No. 1, January pp.3-30 (1998), DOI:10.1145/272991.272995
\bibitem{jump1}2008, H. Haramoto, M. Matsumoto, P. L’Ecuyer, "A Fast Jump Ahead Algorithm for Linear Recurrences in a Polynomial Space", Sequences and Their Applications - SETA 2008, 290--298, DOI:10.1007/978-3-540-85912-3\_26
\bibitem{jump2} 2008, H. Haramoto, M. Matsumoto, T. Nishimura, F. Panneton, P. L’Ecuyer, "Efficient Jump Ahead for F2-Linear Random Number Generators", INFORMS JOURNAL ON COMPUTING, Vol. 20, No. 3, Summer 2008, pp. 385-390 DOI: 10.1287/ijoc.1070.0251
\bibitem{sfmt19937} 2008, M. Saito and M. Matsumoto, "SIMD-oriented Fast Mersenne Twister: a 128-bit Pseudorandom Number Generator", Monte Carlo and Quasi-Monte Carlo Methods 2006, Springer, 2008, pp. 607 -- 622. DOI:10.1007/978-3-540-74496-2\_36
\bibitem{TGSFR}  1992, M. Matsumoto, Y. Kurita, "Twisted GFSR generators". ACM Transactions on Modeling and Computer Simulation. 2 (3): 179–194. doi:10.1145/146382.146383. S2CID 15246234.
\bibitem{knuth} 1998, D. E. Kunth, "The Art of Computer Programming", Seminumerical Algorithms, 3rd ed., Vol. 2. Addison-Wesley, Reading, MA.
\bibitem{intel} 2023, "Intel® 64 and IA-32 Architectures, Optimization Reference Manual"
\end{thebibliography}

%\end{comment}
%\section{References}
%\bibliography{fastbinarysearch}

% --------------------------------------------------- RESULTS  -------------------------------------------------------------------------------
\pagebreak
\appendix

\section{Numerical Results}


\end{document}
