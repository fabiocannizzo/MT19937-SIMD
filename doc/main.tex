\documentclass[preprint,1p,times]{elsarticle}
%\usepackage{a4wide}
%\usepackage{graphicx}
%\usepackage{amsfonts}
%\usepackage{multirow}
%\usepackage{algorithm}
%\usepackage{algpseudocode}
%\usepackage{centernot}
%\usepackage{verbatim}
%\usepackage{algorithmicx}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{float}
\usepackage{comment}
%\usepackage{filecontents}
\usepackage{listings}
%\usepackage[T1]{fontenc}
%\usepackage{float}
%\usepackage[utf8]{inputenc}
%\usepackage[english]{babel}
%\usepackage[margin=0.8in]{geometry}
%\usepackage[hidelinks]{hyperref}
%\usepackage{pgfplots}
%\usepackage{enumitem}
\usepackage{titlesec}
\usepackage{xcolor}
%\usetikzlibrary{patterns}

\titleclass{\subsubsubsection}{straight}[\subsection]

\newcounter{subsubsubsection}[subsubsection]
\renewcommand\thesubsubsubsection{\thesubsubsection.\arabic{subsubsubsection}}
\renewcommand\theparagraph{\thesubsubsubsection.\arabic{paragraph}} % optional; useful if paragraphs are to be numbered

\titleformat{\subsubsubsection}
{\normalfont\normalsize\itshape}{\thesubsubsubsection}{1em}{}
\titlespacing*{\subsubsubsection}
{0pt}{3.25ex plus 1ex minus .2ex}{1.5ex plus .2ex}

\makeatletter
\renewcommand\paragraph{\@startsection{paragraph}{5}{\z@}%
	{3.25ex \@plus1ex \@minus.2ex}%
	{-1em}%
	{\normalfont\normalsize\itshape}}
\renewcommand\subparagraph{\@startsection{subparagraph}{6}{\parindent}%
	{3.25ex \@plus1ex \@minus .2ex}%
	{-1em}%
	{\normalfont\normalsize\itshape}}
\def\toclevel@subsubsubsection{4}
\def\toclevel@paragraph{5}
\def\toclevel@paragraph{6}
\def\l@subsubsubsection{\@dottedtocline{4}{7em}{4em}}
\def\l@paragraph{\@dottedtocline{5}{10em}{5em}}
\def\l@subparagraph{\@dottedtocline{6}{14em}{6em}}
\makeatother

\setcounter{secnumdepth}{4}
\setcounter{tocdepth}{4}


%\pgfplotsset{compat=1.9}

%\pgfplotsset{
%    /pgfplots/ybar legend/.style={
%    /pgfplots/legend image code/.code={%
%       \draw[##1,/tikz/.cd,yshift=-0.25em]
%        (0cm,0cm) rectangle (3pt,0.8em);},
%   },
%5}

%\pgfplotsset{every axis/.append style={
%		font=\footnotesize,
%		line width=0.6pt,
%		}}

%\definecolor{electriccyan}{rgb}{0.0, 1.0, 1.0}
%\definecolor{electricgreen}{rgb}{0.0, 1.0, 0.0}
%\definecolor{ao(english)}{rgb}{0.0, 0.5, 0.0}

%\newcommand\bibsection{\section*{\bibname\markright{\MakeUppercase{\bibname}}}}

\journal{TBD}
% \journal{Journal of Parallel and Distributed Computing}

\begin{document}
	
	%\newenvironment{myitemize}
	%{ \begin{itemize} [topsep= 3pt] %\parskip]
	%    \setlength{\itemsep}{0pt}
	%    \setlength{\parskip}{0pt}
	%    \setlength{\parsep}{0pt}     }
	%{ \end{itemize}                  }
	
	\newcommand {\inred}[1] {\textcolor{red}{#1}}
	%\newcommand {\curle}[1]{ \left \{      #1 \right \}      }
	%\newcommand\XOR{\mathbin{\char`\^}}
	\newcommand\XOR{\mathbin{\oplus}}
	\newcommand\OR{\mid}
	\newcommand\AND{\&}
	\newcommand\myceil[1]{\left\lceil{#1}\right\rceil}
	
	
	
	\begin{frontmatter}
		\title{"VMT19937: A SIMD-Friendly Pseudo Random Number Generator based on Mersenne Twister 19937"}
		
		\author{\renewcommand*{\thefootnote}{\fnsymbol{footnote}}
			Fabio Cannizzo\footnote{DISCLAIMER: Although Fabio Cannizzo is employed by Standard Chartered at the time this paper is written, this paper has been produced by Fabio Cannizzo in a personal capacity and Standard Chartered is not associated or responsible for its content in any way.}}
		
		\begin{abstract}
			Many simulation applications require the generation of long sequences of pseudo-random numbers. Linear recurrences modulo 2 are commonly used as the fundamental building block for constructing pseudo-random number generators with extended periods and excellent statistical properties. These generators consist of a lengthy binary state vector that evolves iteratively through linear recurrences. One widely accepted pseudo-random generator in this category is the Mersenne twister 19937 (MT19937), proposed by Matsumoto and Nishimura \cite{mt19937}, which has been implemented in numerous software libraries and numerical packages. The MT19937's popularity stems from its favorable distribution properties and the simplicity and speed of its algorithm. The linear recurrence responsible for evolving the binary state vector can be expressed as a concise set of elementary bit manipulations. However, this recurrence does not fully utilize the potential for parallelization through SIMD\footnote{Single Instructions Multiple Data} instructions available on modern hardware, limiting further speed enhancements.
			This paper introduces a new SIMD-friendly random number generator, which maintains the same statistical properties and period as the MT19937. It combines the random streams of multiple MT19937 instances with state vectors de-phased via jump-ahead transformations, then polls each instance in a round-robin fashion. By evolving their vector states simultaneously, the new generator achieves perfect vectorization, fully leveraging on SIMD hardware capabilities. Comprehensive test results demonstrate that the throughput of the new generator scales approximately linearly with the width of the SIMD registers used. This provides significant speed improvements, especially on modern CPUs equipped with larger SIMD registers, and allows for efficient generation of random numbers for various simulation applications.
		\end{abstract}
		
		\begin{keyword}
			pseudo-random \sep Mersenne-twister \sep SIMD \sep vectorization \sep SSE \sep AVX \sep AVX512
		\end{keyword}
		
	\end{frontmatter}
	
	%----------------------------------------------------------------------------------------------------------%
	\section{Introduction}
	\label{sec:introduction}
	Many simulation applications necessitate the generation of extensive sequences of pseudo-random numbers. These sequences appear statistically random despite being produced by deterministic and repeatable algorithms, effectively approximating some statistical properties of true randomness.
	
	Various algorithms for pseudo-random number generators (PRNGs) are available, each differing in complexity and approximating distinct properties of true randomness. In specific application domains, the simplest and fastest PRNG that satisfies the required randomness properties is typically adopted. For example, Monte Carlo simulations demand long sequences of random numbers adhering to the central limit theorem's hypothesis, requiring independence and identical distribution among the numbers. Linear recurrences modulo 2 serve as widely used building blocks for constructing PRNGs meeting such requirements. They involve a long binary state vector that evolves iteratively through linear recurrences.
	
	In the domain of finance, one widely accepted pseudo-random generator from this family is the Mersenne twister 19937 (MT19937), proposed by Matsumoto and Nishimura in 1998 \cite{mt19937}. It has found implementation in several software libraries and numerical packages such as Matlab, Octave, NAG, Intel MKL, and the C++ Standard Template Library. Despite the proposal in the literature of more modern generators, also based on linear recurrences modulo 2, such as XORSHIFT \cite{xorshift} and WELL \cite{well}, at present MT19937 remains de facto the most utilized PRNG.
	
	In additional to the good quality of its statistical properties, the success of MT19937 can be attributed to the simplicity of its algorithm. The linear recurrence responsible for evolving the binary state vector can be efficiently implemented with a small set of elementary bit manipulations, resulting in fast execution. However, this recurrence is not amenable to exploiting SIMD operations available on modern hardware for further speed enhancement.
	
	To address this limitation, Saito and Matsumoto proposed SFMT19937 \cite{sfmt19937}, a specialized version of MT19937 designed for architectures with 128-bit wide registers, like Intel SSE and ARM NEON. While SFMT19937 provides significant improvements, it is not generically adaptable to architectures with other register lengths, such as 256-bits (Intel AVX), 512-bits (Intel AVX512), or even wider registers found on GPUs.
	
	This paper introduces a new SIMD-friendly random number generator, which preserve the same statistical properties and period as the MT19937. It combines the random streams of multiple MT19937 instances, each with state vectors de-phased via jump-ahead transformations, then polls each instance in a round-robin fashion. As discussed in \cite{multistream}, the idea of splitting a PRNs sequence into multiple long sub-sequences has already been used to generate multiple independent PRNs streams, which can be consumed by different processing units in parallel. What is new here is that, because these sequences are polled by the same processing unit in round robin fashion, they remain always synchronized and their state vectors can evolve simultaneously. In this way the new generator achieves perfect vectorization, fully leveraging on SIMD hardware capabilities.
	
	\section{Mersenne twister 19937}
	\label{sec:mt19937}
	\subsection{Algorithm description}
	The MT19937 is a pseudo random number generator proposed by Matsumoto and Nishimura \cite{mt19937}.
	Given an initial state $X$ made of $n$ words of $w$ bits each $X=(x_0, x_1, \dots x_{n-1})$, it generates a sequence $\boldsymbol{Z}$ of pseudo random words $z_{0}, z_{1}, \dots, z_{n+P-1}$, with uniform distribution in the range $[0, 2^w-1]$, where $P$ is the period of the generator, after which the sequence of numbers repeats itself. \\
	
	Pseudo random words $z_k$ ($k=0, \dots, P-1$) are generated sequentially via the following algorithm:
	\begin{equation}
		\label{eq:formula}
		\begin{aligned}
			x_{k+n} &= f(x_{k}, x_{k+1},\dots, x_{k+n-1}) \\
			z_k &= g(x_{k+n}) \\
		\end{aligned}
		\quad k=0\dots P-1
	\end{equation}
	To describe the recurrences $f(\cdot)$ and $g(\cdot)$ used in \eqref{eq:formula}, we first introduce some notation. Let $a$ and $b$ be words of $w$ bits and $\alpha$ be an integer in the range $0\le \alpha \le w$ and $A$ be a binary matrix of size $w \times w$:
	\begin{itemize}
		%    \item a bold lowercase variable $\textbf{a}$ refers to a $w$-bits word
		%    \item $(a^0, a^1, \dots, a^{w-1})$ are the individual bits of the word $\textbf{a}$, where $a^0$ is the lease significant bit
		\item $(a \OR b)$ is the bitwise OR of $a$ and $b$
		\item $(a \XOR b)$ is the bitwise XOR of $a$ and $b$
		\item $(a \AND b)$ is the bitwise AND of $a$ and $b$
		\item $(a \gg \alpha)$ is the bitwise SHIFT RIGHT of $a$ by $s$ positions
		\item $(a \ll \alpha)$ is the bitwise SHIFT LEFT of $a$ by $s$ positions
		\item $(a~\%~b)$ is the remainder of the integer division of $a$ and $b$
		\item $a \star A$ is the binary matrix-matrix product in modulo-2, where $a$ is interpreted as a row binary matrix
	\end{itemize}
	Noting that $\&$ has higher priority than $\mid$ and $\star$ has higher priority than $\oplus$, will allow to avoid unnecessary parenthesis and simplify notation.
	
	The recurrence $f(\cdot)$ used in \eqref{eq:formula} to obtain the new element of the state vector is
	\begin{equation}
		\label{eq:step}
		x_{k+n} = f(x_{k},x_{k+1}, \dots, x_{k+n-1}) = x_{k+m} ~\XOR ~\underbrace{\left({x_k}~\AND~h ~\OR~ x_{k+1}~\AND~l\right) }_u \star A 
	\end{equation}
	where
	\begin{itemize}
		\item $h$ and $l$ are $w$-bits constant words defined as $h=\sum_{i=r}^{w-1}2^i$ and $l=\sum_{i=0}^{r-1}2^i$, for some chosen integer $0 \le r \le w-1$ 
		\item $A$ is a constant binary matrix of size $w \times w$
		\item $m$ is an index chosen in the range $0 \le m < n$
		\item $r$ is a separation point in the words in the range $0 \le r \le w-1$
	\end{itemize}
	
	The matrix $A$ has a particular structure chosen so that the vector matrix multiplication $(u\star A)$ can be carried out quickly with just a few simple bit manipulations. Let $(a_0, a_1, \dots, a_{w-1})$ the individual bits of some constant word $a$, where $a_0$ is the least significant bit, and $I_{w-1}$ a binary identity matrix of size $(w-1)$
	\begin{equation}
		\label{eq:matmult}
		A = \left[ \begin{matrix} 0 & I_{w - 1} \\ a_{w-1} & (a_{w - 2}, \ldots , a_0) \end{matrix} \right] \quad \implies \quad u\star A = \begin{cases}u \gg 1 & \text{if $u$ is even}\\(u \gg 1) \oplus a & \text{if $u$ is odd}\end{cases}
	\end{equation}
	
	Note that although the stored state vector has size $nw$ bits, the lower $r$ bits of $x_k$ are not used in recurrence \eqref{eq:step} and after the recurrence is complete they are discarded, so the effective dimension of the state vector is only $nw-r$ bits. \\ % This determines the period of the generator $P=2^{nw-r}-1$.
	
	The transformation $g(\cdot)$, called tempering, is also chosen to be quickly computable. For some chosen value of the $w$-bits constant words $d$, $b$, $c$, and some chosen values of the constants $\alpha$, $\beta$, $\gamma$ and $\delta$ in the range $[0,32]$, $z=g(x)$ is obtained via the sequence of transformations
	\begin{equation}
		\label{eq:tempering}
		\begin{aligned}
			y &= x \oplus ((x\gg \alpha)~\And~d)\\
			y &= y \oplus ((y\ll \beta)~\And~b)\\
			y &= y \oplus ((y\ll \gamma)~\And~c)\\
			z &= y \oplus (y\gg \delta)
		\end{aligned}
	\end{equation}
	
	The chosen value for all the above parameters are:
	\begin{equation}
		\label{eq:params}
		\begin{aligned}
			(w, n, m, r) &= (32, 624, 397, 31)\\
			a &= \textrm{9908B0DF}\\
			(\alpha, d) &= (11, \textrm{FFFFFFFF})\\
			(\beta, b) &= (7, \textrm{9D2C5680})\\
			(\gamma, c) &= (15, \textrm{EFC60000})\\
			\delta &= 18\\
		\end{aligned}
	\end{equation}
	where the words $a$, $d$, $b$ and $c$ are expressed in hexadecimal format. These choice of parameters yield a huge generator period $P=2^{nw-r}-1=2^{19937}-1$ and good K-distribution properties of the generator.
	
	\subsection{Implementation}
	For each new random word generated in \eqref{eq:formula} the state vector is transformed by \eqref{eq:step} removing the least significant word $x_{k}$ on its left side and adding a new word $x_{k+n}$ on its right side. Starting with an initial state vector $X_0=(x_0, x_1, \dots, x_{n-1})$, the state vector evolves as
	$$
	\begin{matrix}
		X_0 &=& x_0 & x_1 & \dots & x_{n-1} &\\
		X_1 &=& & x_1 & x_2 & \dots & x_{n} & \\
		X_2 &=& & & x_2 & \dots & \dots & x_{n+1} &\\
		\cdots \\
	\end{matrix}
	$$
	This can be effectively implemented as a circular buffer of size $n$, which avoids shifting the position of each word inside the vector at each iteration.
	\begin{equation}
		\label{eq:staterec}
		\begin{matrix}
			X_0 &=& x_0 & x_1 & x_2 & \dots & x_{n-1} \\
			X_1 &=& x_{n} & x_1 & x_2 & \dots & x_{n-1} \\
			X_2 &=& x_{n} & x_{n+1} & x_2 & \dots & x_{n-1} \\
			\cdots \\
		\end{matrix}
	\end{equation}
	Recurrence \eqref{eq:step} can be rewritten in terms of the circular buffer by taking the modulo-$n$ of all indices.
	\begin{equation}
		\label{eq:stepmod}
		x_{k\%n} = x_{(k+m)\% n} \XOR \left[ \left(({x_{k\%n}}~\AND~h) \OR (x_{(k+1)\%n}~\AND~l)\right) \star A \right]
	\end{equation}
	Note that after $n$ steps, i.e. repeating \eqref{eq:stepmod} $n$ times, all elements of the state vector are replaced by new ones. To remove the modulo-$n$ operator from the array indices, the loop which generates an entirely new state vector can be broken in 3 sub-loops, depending on when the 3 indices $k$, $k+1$ and $k+m$ become equal to $n$.
	\begin{equation}
		\label{eq:stepnomod}
		x_k = \left\{
		\begin{aligned}
			x_{k+m}   & ~~\XOR & ( & x_{k} ~\AND~ h & \OR~ & x_{k+1} ~\AND~ l & ) &~\star~ A &\quad &k = 0, \dots, n-m-1\\
			x_{k+m-n} & ~~\XOR & ( & x_{k} ~\AND~ h & \OR~ & x_{k+1} ~\AND~ l & ) &~\star~ A &\quad &k = n-m, \dots, n-2 \\
			x_{k+m-n} & ~~\XOR & ( & x_{k} ~\AND~ h & \OR~ & x_{0}   ~\AND~ l & ) &~\star~ A &\quad &k = n-1
		\end{aligned}
		\right.
	\end{equation}
	After the state vector has been advanced by $n$ steps, $n$ new pseudo random words can be produced by applying transformation \eqref{eq:tempering} to the new state elements.
	
	\subsection{Vectorization obstacles}
	The specific parameters \eqref{eq:params} chosen for the MT19937 are $w=32$, $n=624$, $r=31$ and $m=397$, so in order to generate an entirely new state vector the first instruction in \eqref{eq:stepnomod} needs to be executed 227 times, the second one 396 times and the last one just once. Vectorization consists in packing operations carried out in loops \eqref{eq:stepnomod} so that multiple iterations can be done simultaneously using SIMD instructions. For instance, SSE2 registers are 128 bits wide and allow to pack 4x32-bit words operations into a single operation. The first instruction in \eqref{eq:stepnomod} could be implemented in vectorial format as:
	\begin{align}
		\label{eq:stepsse2}
		\begin{pmatrix}x_{k} \\ x_{k+1} \\ x_{k+2} \\ x_{k+3} \end{pmatrix}
		&= \begin{pmatrix}x_{k+m} \\ x_{k+1+m} \\ x_{k+2+m} \\ x_{k+3+m} \end{pmatrix} ~\XOR~ \left(\begin{pmatrix}x_{k} \\ x_{k+1} \\ x_{k+2} \\ x_{k+3} \end{pmatrix}~\AND~h ~\OR~ \begin{pmatrix}x_{k+1} \\ x_{k+2} \\ x_{k+3} \\ x_{k+4} \end{pmatrix}~\AND~l\right) \star A \quad && k=0, 4, \dots, 220 \\
		\label{eq:stepssescalar}
		x_k &= x_{(k+m)} ~\XOR~ \left(x_{k}~\AND~h ~\OR~ x_{k+1}~\AND~l\right) \star A \quad &&k = 224, 225, 226
	\end{align}
	Because 227 is not a perfect multiple of 4, the best which can be done is to carry out 56 iterations in packs of 4 as in \eqref{eq:stepsse2}, then some special handling is needed for the last 3 iterations in \eqref{eq:stepssescalar}. Similar considerations would apply using SIMD registers of different width, e.g. AVX registers, which are 256-bits wide or AVX512 registers which are 512-bits wide.
	
	A second issue is that the tuples $(x_k, x_{k+1}, x_{k+2}, x_{k+2})$ appearing in \eqref{eq:stepsse2} are in general not perfectly aligned in memory. For example, if the tuple $(x_k, x_{k+1}, x_{k+2}, x_{k+3})$ was stored at a memory address which is a perfect multiple of 16 (the size in bytes of an SSE2 register), then the tuple $(x_{k+1}, x_{k+2}, x_{k+3}, x_{k+4})$ would be stored at a memory address incremented by 4 bytes, which cannot be a multiple of 16. Similarly the tuple $(x_{k+m}, x_{k+1+m}, x_{k+2+m}, x_{k+3+m})$ would be stored at a memory address incremented by 397x4 bytes, which, since $m=397$, cannot be a multiple of 16 either. Because of hardware limitations, the lack of memory alignment causes slow load and save memory operations, at least on x86-64 CPUs (see \cite{intel} sections 6.3, 15.6 and 18.23).
	
	\section{Vectorial Mersenne twister 19937 (VMT19937)}
	\label{sec:simdgen}
	In this section, we introduce a novel random number generator that utilizes multiple MT19937 generators as building blocks and combines their random number streams to produce a new sequence of random numbers. This new generator preserves the same statistical properties and period as the original MT19937, but it is specifically designed to be SIMD friendly. As a result, its throughput scales proportionally to the length of the SIMD registers available on the hardware. We name this new generator \textit{Vectorial Mersenne twister 19937}, or, in abbreviated form, \textbf{VMT19937}.
	Given a certain initial state $X_0$, the MT19937 PRNG produces a sequence $\boldsymbol{Z}$ of PRNs $z_k$
	\begin{equation}
		\label{eq:mainseq}
		\boldsymbol{Z} = z_0, z_1, \dots, z_{P-1} 
	\end{equation}
	These numbers are independent and identically distributed, or at least, they emulate such statistical properties. They have uniform discrete distribution in $[0, 2^{32}-1]$, and the sequence has a period of $P=2^{19937}-1$.
	
	Let's consider $M$ sub-sequences $\boldsymbol{Z_t}$ ($t=0\dots M-1$) of equal size $J$ obtained by partitioning the first $M\cdot J$ numbers of sequence $\boldsymbol{Z}$ in groups of equal length $J$
	\begin{equation}
		\label{eq:subseq}
		\underbrace{z_0, z_1, \dots, z_{J-1}}_{\boldsymbol{Z_0}},\, \underbrace{z_J, z_{J+1}, \dots, z_{2J-1}}_{\boldsymbol{Z_1}}, \dots,\, \underbrace{z_{(M-1)J}, z_{(M-1)J+1}, \dots, z_{MJ-1}}_{\boldsymbol{Z_{M-1}}}
	\end{equation}
	Let's construct a new sequence $\boldsymbol{S}$ which interleaves the sequences $\boldsymbol{Z_t}$
	\begin{equation}
		\label{eq:combseq}
		\boldsymbol{S}=\underbrace{z_0, z_J, z_{2J}, \dots, z_{(M-1)J,}}_{\text{1-st number from each sub-sequence}} \,\underbrace{z_1, z_{J+1}, z_{2J+1}, \dots, z_{(M-1)J+1},}_{\text{2-nd number from each sub-sequence}}\, \dots, \underbrace{z_{J-1}, z_{2J-1}, z_{3J-1}, \dots, z_{MJ-1}}_{\text{$J$-th number from each sub-sequence}}
	\end{equation}
	Because the numbers in the original sequence $\boldsymbol{Z}$ are independent and identically distributed, the numbers in the new sequence $\boldsymbol{S}$, obtained by interleaving the sub-sequences $\boldsymbol{Z_t}$, are also independent and identically distributed. The period of the new sequence is $MJ$, so if $J$ is chosen as $P/M$, then the new sequence has the same period as the original one. Note that, since $P$ might not be divisible by $M$, we choose $J$ so that the first $P \% M$ sequences have length $J=\myceil{P/M}$ and the last $P - P \% M$ sequences have length $J-1$, which preserves the total original period $P$. \\
	
	Let $L$ be the SIMD register size expressed in number of bits available on a certain CPUs, which can be 128, 256 or 512 depending if the CPU supports only SSE2, AVX or AVX512 instructions, we choose $M$ as the number of 32-bit words which fits in the SIMD registers, i.e. $M=L/32$.
	We can think about $M$ as the vectorization coefficient, i.e. the number of 32-bit operations which can be performed in parallel using vectorial instructions.
	Then we divide the total periods of the Mersenne twister $P=s^{19937}-1$ in $P \% M$ sub-sequences of length
	$$J=\myceil{\frac{P}{M}}=2^{19937-\log_2M}$$
	with the last $P - P \% M$ sequences having length $J-1$. Table \ref{tab:jvalues} shows the parameters $L$, $M$ and $J$ for various SIMD architectures, including the special case $M=1$, which yields the original undivided MT19937 sequence \eqref{eq:mainseq}.
	
	\begin{table}[h!]
		\centering
		\begin{tabular}{|c | c | c | c | c | c|} 
			\hline
			\vspace{-10pt}  & \vspace{0pt} & \vspace{0pt}& \vspace{0pt}& \vspace{0pt}& \vspace{0pt} \\
			SIMD   & L   & M & J & $P \% M$ & $P-P \% M$ \\
			\hline
			\vspace{-9pt}  & \vspace{0pt} & \vspace{0pt}& \vspace{0pt}& \vspace{0pt}& \vspace{0pt} \\
			n.a.   & 32  & 1 & $2^{19937}-1$  & 1  & 0 \\		
			\hline
			\vspace{-9pt}  & \vspace{0pt} & \vspace{0pt}& \vspace{0pt}& \vspace{0pt}& \vspace{0pt} \\
			SSE2   & 128 & 4 & $2^{19935}$  & 3  & 1 \\		
			\hline
			\vspace{-9pt}  & \vspace{0pt} & \vspace{0pt}& \vspace{0pt}& \vspace{0pt}& \vspace{0pt} \\
			AVX    & 256 & 8 & $2^{19934}$  & 7  & 1 \\		
			\hline
			\vspace{-9pt}  & \vspace{0pt} & \vspace{0pt}& \vspace{0pt}& \vspace{0pt}& \vspace{0pt} \\
			AVX512 & 512 & 16 & $2^{19933}$ & 15 & 1 \\		
			\hline
		\end{tabular}
		\caption{\label{tab:jvalues} VMT19937 parameters $L$, $M$ and $J$ for various SIMD architectures.}
	\end{table}
	
	A PRNG which produces the sequence $\boldsymbol{S}$ is constructed by duplicating $M$ times the original MT19937 generator with initial state $X_0$, thus obtaining an array of $M$ MT19937 generators $G_t$ ($t=0,\dots, M-1$) with identical state vector $X_0$. Then we advance the state vector of each generator $G_t$ by $(t\cdot J)$ steps, so that it will produce the sequence $\boldsymbol{S_t}$. Last we combine the array of generators $G_t$ ($t=0,\dots, M-1$) into a single new generator, which produces a sequence by polling each of the $G_t$ generators in round robin mode, i.e. it produces the desired sequence $\boldsymbol{S}$.
	
	Let's add a second index $t$ to the state vector, so that $X_{k,t}$ is the state $k$-th for the $t$-th generator, i.e. $X_{0,t}=X_{tJ}$, the multi-generator described below has initial state
	$$
	\begin{pmatrix}
		X_{0,0} \\ X_{0,1} \\ \vdots \\ X_{0,M-1}
	\end{pmatrix}
	= 
	\begin{pmatrix}
		x_{0,0} & x_{1,0} & \cdots & x_{n-1,0} \\
		x_{0,1} & x_{1,1} & \cdots & x_{n-1,1} \\
		\cdots \\
		x_{0,M-1} & x_{1,M-1} & \cdots & x_{n-1,M-1} \\
	\end{pmatrix}
	$$
	By interleaving in memory the words of the state vectors of the $M$ generators, we obtain for the multi-state generator a combined state vector $\hat{X}_0$
	$$
	\hat{X}_0 = [(x_{0,0}, x_{0,1}, \dots x_{0,M-1}), (x_{1,0}, x_{1,1}, \dots x_{1,M-1}), \dots (x_{n-1,0}, x_{n-1,1}, \dots x_{n-1,M-1})]
	$$
	This allows to transform each of the 32-bits operations in \eqref{eq:step} into a $L$-bits operation which advances by one step the $M$ state vectors simultaneously, hence reducing computation cost by a factor $M$.
	\begin{align}
		\label{eq:msmt19937}
		\begin{pmatrix}x_{k,0} \\ x_{k,1} \\ \vdots \\ x_{k,M-1} \end{pmatrix}
		&= \begin{pmatrix}x_{k+m, 0} \\ x_{k+m,1} \\ \vdots \\ x_{k+m,M-1} \end{pmatrix} ~\XOR~ \left(\begin{pmatrix}x_{k,0} \\ x_{k,1} \\ \vdots \\ x_{k,M-1} \end{pmatrix}~\AND~h ~\OR~ \begin{pmatrix}x_{k+1,0} \\ x_{k+1,1} \\ \vdots \\ x_{k+1,M-1}  \end{pmatrix}~\AND~l\right) \star A
	\end{align}
	
	\subsection{Computation of the initial state vectors $X_{tJ}$}
	To construct the generator described in section \ref{sec:simdgen}, we need to advance the state vector $X_0$ by $J$ steps. In theory, we could apply recurrence \eqref{eq:step} $J$ times. However, in practice, since $J$ is a huge number, this operation would be astronomically expensive. 
	To overcome this, techniques known as \textit{jump ahead} are used to compute the state $X_{tJ}$ directly from $X_0$ without calculating all the intermediate states.
	
	\subsubsection{\textit{Jump ahead} via binary matrix multiplications modulo 2}
	\label{sec:jumpahead}
	The simplest \textit{jump ahead} methodology for the MT19937 is based on binary matrix multiplications modulo 2, as proposed by Knuth \cite{knuth}. Let $Y$ be a subset of the state vector $X$, with the first $r$ bits (where $r = 31$) removed since they are not used in recurrence \eqref{eq:step}. 
	The effective state vector $Y$ is a binary matrix with dimensions $1\times (nw-r)$. Advancing the effective state vector $Y_k$ to $Y_{k+1}$ using \eqref{eq:step} is equivalent to the binary vector-matrix multiplication modulo-2:
	\begin{equation}
		Y_{k+1} = Y_k \star F
	\end{equation}
	where $F$ is a square binary matrix of size $wn-r$
	\begin{equation}
		\label{eq:transmat}
		F = \begin{pmatrix}
			0 & I_w & 0 & \cdots & &  &  &  & 0 \\
			\vdots & 0 & I_w & 0 & \cdots & & & & 0\\
			0 & \vdots & 0 & \ddots & &&& & \vdots \\
			I_w & 0 & \vdots & & \ddots & && & \vdots \\
			0 & \vdots &  & & & \ddots & & & \vdots \\
			\vdots &  &  &  & &&& I_w & 0 \\
			0 &  &  & &  & &&&I_{w - r} \\
			A & 0 & \cdots & &  &  &&& 0
		\end{pmatrix}
		\begin{matrix}
			\\ \\ \\ \leftarrow m\text{-th row} \\ \\ \\ \\
		\end{matrix}
	\end{equation}
	State $X_{tJ}$ can be computed as
	\begin{equation}
		\label{eq:jumpahead}
		Y_{tJ} = Y_{tJ-1} \star F = Y_{tJ-2}  \star F \star F = \ldots = Y_{(t-1)J}  \star F^{J}, \quad j=1,\dots,M-1
	\end{equation}
	Let $B=F^J$, since $J$ is a power of 2 ($J=2^{q}$, where $q=19933$)
	$$
	B=F^{J}=F^{2^q}=F^{2^{q-1}} \star F^{2^{q-1}}
	$$
	suggesting the following simple algorithm to compute $B$
	$$
	F^{2^q} = F^{2^{q-1}} \star F^{2^{q-1}}, \quad q=1, 2, \dots, 19333
	$$
	The computation of $B=F^{2^{19933}}$ involves 19933 matrix square operations and takes several hours when using SIMD-optimized code on a 32-core machine. This computation can be done offline, and the resulting matrix $B$ can be stored for later use. Storing $B$ requires approximately 47Mb of space ($19937^2/8$ bytes), but it can be compressed to only 296Kb using LZMA2 compression.
	
	The overhead associated with initializing the generator state vectors as in \eqref{eq:jumpahead}, which requires $M-1$ vector-matrix multiplications, is negligible in the context of generating a large stream of PRNs.
	
	\subsubsection{Alternative \textit{jump ahead} methods}
	It is worth noting that there exist more efficient \textit{jump-ahead} algorithms that do not require storing the jump matrix and are faster than performing a vector-matrix multiplication as in \eqref{eq:jumpahead}. Examples of such algorithms can be found in \cite{jump1} and \cite{jump2}. However, these algorithms have not been discussed here, as the one adopted in section \ref{sec:jumpahead} is simpler to implement and is already very fast.\\
	
	Furthermore, the main contribution of this paper is the vectorization of the algorithm to advance the state vector. If a more efficient \textit{jump-ahead} method were to be adopted, it would further improve initialization time, but it would not invalidate any of the arguments presented in this paper regarding the algorithm's throughput.
	
	\section{VMT19937 implementation details}
	An implementation of the multi-state generator described in section \ref{sec:simdgen} is available on github\footnote{\label{fn:github} https://github.com/fabiocannizzo/VMT19937}. It uses a few optimization techniques introduced to speed up SIMD computations.
	
	\subsection{Memory alignment}
	The state vector array $\hat{X_k}$ is memory-aligned on a 64-byte boundary, i.e. its starting address is a multiple of 64 bytes. This ensures that the data is aligned with cache lines, minimizing the risk of cache misses\footnote{a cache miss fault is a performance penalty paid when a piece of requested data is not available in cache} or cache split\footnote{a cache split fault is a performance penalty paid when a piece of requested data is located in two different cache lines} faults. As a result, it leads to efficient memory access and improved performance, which is  crucial when performing vectorized operations on the state vector using SIMD instructions.
	
	\subsection{Avoid code branches when regenerating the state vector}
	The vector-matrix multiplication in \eqref{eq:matmult} involves resolving conditional code. In C++ notation, this can be represented as \lstinline{(w % 2 ? w ^ a : w)}.
		
		When $w$ and $a$ are scalar words, an efficient implementation can be achieved by avoiding expensive code branches and using a \textit{conditional-move} instruction (e.g., the \textit{CMOVxx} assembler instructions in Intel \textit{x86-64}). Alternatively, as seen in the original MT19937 code, it can be implemented by defining an array \lstinline|tmp[2]={0, a}| and using the result of \lstinline{(w % 2)} as an index into this array, i.e. \lstinline{tmp[w % 2]}.
			
			When $w$ and $a$ are SIMD vectors, the implementation is also optimized to avoid costly code branches using special SIMD instructions and bit masking. For example, with SSE2 instructions, it becomes \lstinline{(((w & 1) > 0) & a)}, where $w$, $a$, $1$, and $0$ are SIMD vectors. This approach leverages the SSE2 SIMD comparison '$>$', which returns a mask with all bits set to ones or zeros for each packed word, depending on whether the comparison is true or false.
			
			\subsection{Vectorize tempering}
			The sequence of loops in \eqref{eq:stepnomod} generates an entirely new state vector, which needs to be consumed word by word to produce random numbers via \textit{tempering}, as shown in \eqref{eq:tempering}. To facilitate this process, we use the variable \textit{nUsed} to keep track of how many state elements have already been used. This variable is reset to zero every time the state vector is regenerated. The pseudo-code for querying one random number from the generator is as follows:
			\begin{verbatim}
				int32 getRandom() {
					if (nUsed == stateVectorSize) {
						regenerateStateVector();
						nUsed = 0;
					}
					return temper(stateVector[nUsed++]);
				}
			\end{verbatim}
			However, tempering the numbers one at a time does not allow us to use vectorized tempering. To address this limitation, we introduce a small buffer with the same size as one cache line, where we can store a few tempered numbers for efficient processing. The updated pseudo-code for querying random numbers is as follows:
			\begin{verbatim}
				int32 getRandom() {
					if (nUsedInTemperedBuffer == temperedBufferSize) {
						if (nUsed == stateVectorSize) {
							regenerateStateVector();
							nUsed = 0;
						}
						refillVectorizedTemperedBuffer();
						nUsedInTemperedBuffer = 0;
					}
					return temperedBuffer[nUsedInTemperedBuffer++];
				}
			\end{verbatim}
			\subsection{Avoiding code branches when querying for random numbers}
			\label{seq:blocks}
			Checking if all elements of the tempered numbers buffer have been used comes with some inherent cost. When the operations \textit{regenerateStateVector} and \textit{temper} are relatively slow compared to this check, the cost of the check is negligible. However, as these operations get vectorized and become very fast, the relative cost of this check increases significantly and becomes material. To address this concern, we have introduced the ability to query the generator in blocks of numbers. There are two options for querying: using blocks of the same size as the buffer of tempered numbers or using blocks of the same size as the entire state vector. Both these query modes allow us to optimize the query process and efficiently utilize the generator's performance.
			
			\section{Test results}
			
			\subsection{Statistical tests}
			As discussed in section \ref{sec:simdgen} the VMT19937 generator produces a sequence of independent and identically distributed PRNs. Since it uses the MT19937 generator as a building block, we expect the probabilistic quality of the sequence of numbers it generates to be the same. This is confirmed by empirically testing the generator via the excellent \textit{TestU01} test suite proposed by Simar and L'Ecuyer in \cite{testu01}. We observe that almost all tests pass, which is the same results obtained with the MT19937.
			
			\subsection{Performance tests}
			\label{sec:tests}
			Table \ref{tab:results} illustrates the computation time required to generate 5 billion uniform discrete 32-bit random numbers on different CPUs with various implementations of the generator and configurations.
			In row 1, MT19937 refers to the original Mersenne twister 19937 implementation, as downloaded from Matsumoto's web site\footnote{\label{fn:orig}http://www.math.sci.hiroshima-u.ac.jp/m-mat/MT/MT2002/CODES/mt19937ar.c}. Its state is composed by 624 words of 32-bits each.
			In row 2, SFMT19937 refers to the original SFMT 19937 implementation, also downloaded from Matsumoto's web site\footnote{http://www.math.sci.hiroshima-u.ac.jp/m-mat/MT/SFMT/SFMT-src-1.5.1.zip}. Its state is composed by 156 words of 128-bits each\footnote{the number of words is computed a $(19937 / 128 + 1)=156$}.
			In the remaining rows, VMT19937 refers to the new implementation proposed in section \ref{sec:simdgen}, where the prefix $X$ stands for \textit{multi-state}, and is parameterized by the number of states $M$.
			The \textit{Word} and \textit{Size} columns show respectively the width of the words used in the state vector and and the number of words composing it.
			For VMT19937 each test is repeated querying the generator for blocks of random numbers of different size:
			\begin{itemize}
				\item in scalar mode (\textit{QueryBlock}=1), we query the generator for one random number per function call
				\item in vectorial mode (\textit{QueryBlock}=16), we query the generator for blocks of 16 random number per function call. Note that 16 is the size in words of the largest possible SIMD register used acroos all tests (512-bits with AVX512). This avoids...
				\item in vectorial mode (\textit{QueryBlock}=\textit{StateSize}), we query the generator for blocks of random number of the same size as the state vector size. This avoids ...
			\end{itemize}
			A C++ implementation of VMT19937 and of the test benchmark reported in table \ref{tab:results} is available on github\footnote{github repository: https://github.com/fabiocannizzo/VMT19937}. The executable programs have been compiled with \textit{g++ 11.3} targeting \textit{x86-64} architecture. The column \textit{CompileTarget} refers to the SIMD instruction set used:
			\begin{itemize}
				\item rows 1 to 6 are produced with compilation flags \textit{"-O3 -msse4.2"}
				\item rows 7 to 9 are produced with compilation flags \textit{"-O3 -mavx2"}
				\item rows 10 to 12 are produced with compilation flags \textit{"-O3 -mavx512f -mavx512dq"}
			\end{itemize}
			Test have been run on different CPUs. Note that results for some CPUs are not available because the chosen instruction set is not supported on those particular CPUs. The CPUs referenced in table \ref{tab:results} have specifications:
			\begin{enumerate}
				\item CPU-1: Intel(R) Celeron(R) J4125, cache 4Mb, frequency 2.0 GHz, burst frequency 2.7 GHz, SIMD support for SSE4.2. This is a low end CPU.
				\item CPU-2: Intel® Core™ i9-12900H, cache 24Mb cache, base frequency 3.8GHz, turbo frequency 5.0 GHz, SIMD support for AVX2. This is a high performance modern laptop CPU.
				\item CPU-3: Intel® Xeon® Gold 6234, cache 24.75Mb, base frequency 3.3GHz, turbo frequency 4.0 GHz, SIMD support for AVX512. This is a high performance modern desktop CPU.
			\end{enumerate}
			
			
			\begin{table}
				\begin{tabular}{c|c| c|c| c| c| c| c|c|c|} 
					\cline{2-10}
					&  \multicolumn{2}{c|}{Implementation}   & \multicolumn{2}{c|}{State} & Query & Compile & \multicolumn{3}{c|}{Time (seconds)} \\
					\cline{1-5} \cline{8-10} \multicolumn{1}{|c|}{Row}
					& Generator  & M   & Word & Size & block & target & CPU-1 & CPU-2 & CPU-3 \\
					\hline \multicolumn{1}{|c|}{1}
					& MT19937         &  n.a. & 32   & 624 & 1     & SSE2    & 31.56 & 20.07 & 16.90 \\ 
					\hline \multicolumn{1}{|c|}{2}
					& SFMT19937       &  n.a. & 128  & 156 & 1     & SSE2    & 21.67 & 6.99 & 9.97 \\
					\hline \multicolumn{1}{|c|}{3}
					& VMT19937    & 1   & 32   & 624 & 1     & SSE2    & 20.83  & 11.10 & 13.54 \\
					\hline \multicolumn{1}{|c|}{4}
					& VMT19937    & 4   & 32  & 2496 & 1     & SSE2    & 13.28  & 6.19 & 7.14 \\
					\hline \multicolumn{1}{|c|}{5}
					& VMT19937    & 4   & 32  & 2496 & 16    & SSE2    &  7.77  & 3.59 & 4.19 \\
					\hline \multicolumn{1}{|c|}{6}
					& VMT19937    & 4   & 32  & 2496 & 2496  & SSE2    &  7.42  & 3.37 & 4.59 \\
					\hline \multicolumn{1}{|c|}{7}
					& VMT19937     & 8   & 32  & 4992 & 1    & AVX     & n.a.   &5.43  & 6.42 \\
					\hline \multicolumn{1}{|c|}{8}
					& VMT19937     & 8   & 32  & 4992 & 16   & AVX     & n.a.   &2.15  & 2.15 \\
					\hline \multicolumn{1}{|c|}{9}
					& VMT19937     & 8   & 32  & 4992 & 4992 & AVX     & n.a.   &2.10 & 2.06 \\
					\hline \multicolumn{1}{|c|}{10}
					& VMT19937   &  16   & 32  & 9984 & 1    & AVX512  & n.a.   & n.a. & 5.66 \\
					\hline \multicolumn{1}{|c|}{11}
					& VMT19937   &  16 & 32    & 9984 & 16   & AVX512  & n.a.   & n.a. & 1.45 \\
					\hline \multicolumn{1}{|c|}{12}
					& VMT19937   &  16  & 32    & 9984 & 9984 & AVX512  & n.a.   & n.a. & 1.14 \\
					\hline
				\end{tabular}
				\caption{\label{tab:results} Time in seconds to generate 5 billions uniform discrete 32-bit random numbers.}
			\end{table}
			
			\subsubsection{Observations}
			Although the VMT19937 with $M=1$ is identical to the original MT19937 from an algorithm point of view, we observe that the implementation of VMT19937 is generally faster. This improvement in speed is mainly due to inlining, as MT19937 is written as a C file and every invocation results in a function call, while VMT19937 is written as a header file and allows the compiler to produce more optimized code. To ensure a fair comparison that measures solely the improvement associated with the new algorithm, we will use row 3 (VMT19937 with M=1) as the baseline for comparison.
			
			In rows 4, 5, and 6, we observe the computation time of VMT19937 with M=4 when querying random numbers individually, in blocks of 16 (the size of a cache line), and in blocks of 2496 (the size of the entire state vector). We notice a significant performance improvement as the query block size increases from 1 to 16, and only a marginal additional improvement when the query block size grows from 16 to 2496. The reason for this improvement is explained in section \ref{seq:blocks}. Similar patterns are observed in rows 7 to 9 and rows 10 to 12 for generators VMT19937 with M=8 and M=16, respectively. The performance gains associated with larger query block sizes are consistent across multiple configurations of the generator and become relatively more important as the size of the SIMD register increases and the operations of updating the state become faster.
			
			In rows 3, 4, 7, and 10, we observe that the computation time of the VMT19937 generator reduces with $M$, i.e., the length of the SIMD registers. However, the throughput increase is not proportional to $M$ because, as explained in section \ref{seq:blocks}, the cost of checking if we have exhausted the state vector and need to regenerate it starts to dominate over the cost of regenerating the state. The situation improves significantly for rows 5, 8, and 11, where we query random numbers in blocks of 16, and therefore we dilute the cost of checking if we have exhausted the state vector by a factor of 16.
			
			In rows 6, 9, and 12, we observe that when the block query size changes from 16 to the size of the full state vector, the throughput increases even more. For example, for CPU-3, which is the most modern CPU, in rows 6 and 9, we observe that when $M$ grows by a factor of 2 (from 4 to 8), the computation time decreases from 4.59s to 2.06s, approximately a factor of 2. Similarly, in rows 9 and 12, we observe that when $M$ grows by a further factor of 2 (from 8 to 16), the computation time decreases from 2.06s to 1.14s, i.e., approximately a factor of 2 again.
			
			These comprehensive results demonstrate that the throughput of the VMT19937 increases with the size of the SIMD registers $M$. Requesting PRNs in blocks amortizes the cost of checking if the state vector is exhausted and allows to measure the pure cost of updating the state vector, which scales up proportionally to the size of the SIMD registers $M$.
			
			\section{Conclusion}
			In this paper, we introduced the new random number generator VMT19937, which utilizes multiple independent random streams generated by the traditional MT19937. These streams are combined with de-phased state vectors through a jump ahead initialization technique. The comprehensive test results demonstrated that perfect vectorization is achieved, resulting in a throughput that scales approximately linearly with the length of the available SIMD registers when random numbers are queried in blocks. This allows for faster generation of random numbers on modern CPUs with larger SIMD registers compared to the original MT19937 algorithm.
			
			One key advantage of VMT19937 is that it does not require re-calibration of the parameters of the underlying MT19937 generator. Additionally, the technique has the potential to be applied to other linear congruential generators, as long as an effective jump ahead methodology exists.
			
			Furthermore, while we illustrated the implementation with SIMD instructions, the generality of this technique suggests its applicability to other vectorial processing systems, such as GPUs or FPGAs.
			
			Overall, VMT19937 offers an efficient and flexible solution for generating random numbers with SIMD-friendly characteristics, making it a valuable addition to the repertoire of PRNGs.
			
			%------------------------------BIBLIOGRAPHY-----------------
			\begin{thebibliography}{9}
				
				\bibitem{TGSFR} 1992, M. Matsumoto, Y. Kurita, ``Twisted GFSR generators''. ACM Transactions on Modeling and Computer Simulation. 2 (3): 179--194. DOI: 10.1145/146382.146383.
				
				\bibitem{mt19937} 1998, M. Matsumoto, T. Nishimura, ``Mersenne Twister: A 623-dimensionally equidistributed uniform pseudorandom number generator'', ACM Trans. on Modeling and Computer Simulation, 8(1), 3-30. DOI: 10.1145/272991.272995.
				
				\bibitem{knuth} 1998, D. E. Kunth, ``The Art of Computer Programming'', Seminumerical Algorithms, 3rd ed., Vol. 2. Addison-Wesley, Reading, MA.
				
				\bibitem{ecuyer} 2002, P. L’Ecuyer, R. Simard, E. J. Chen, W. D. Kelton, ``An object-oriented random-number package with many long streams and substreams." Oper. Res. 50 1073--1075.
				
				\bibitem{xorshift} 2003, G. Marsaglia. ``Xorshift RNGs''. Journal of Statistical Software. 8 (14). DOI: 10.18637/jss.v008.i14
				
				\bibitem{well} 2006, F. Panneton; P. L'Ecuyer; M. Matsumoto. ``Improved long-period generators based on linear recurrences modulo 2''. ACM Transactions on Mathematical Software. 32 (1): 1--16. DOI: 10.1145/1132973.1132974.
				
				\bibitem{testu01} 2007, P. L'Ecuyer and R. Simard, ``TestU01: A C Library for Empirical Testing of Random Number Generators''. ACM Transactions on Mathematical Software, Vol. 33, article 22.
				
				\bibitem{jump1} 2008, H. Haramoto, M. Matsumoto, P. L’Ecuyer, ``A Fast Jump Ahead Algorithm for Linear Recurrences in a Polynomial Space'', Sequences and Their Applications - SETA 2008, 290--298, DOI: 10.1007/978-3-540-85912-3\_26
				
				\bibitem{jump2} 2008, H. Haramoto, M. Matsumoto, T. Nishimura, F. Panneton, P. L’Ecuyer, ``Efficient Jump Ahead for F2-Linear Random Number Generators'', Informs Journal On Computing, Vol. 20, No. 3, Summer 2008, pp. 385-390
				
				\bibitem{sfmt19937} 2008, M. Saito and M. Matsumoto, ``SIMD-oriented Fast Mersenne Twister: a 128-bit Pseudorandom Number Generator'', Monte Carlo and Quasi-Monte Carlo Methods 2006, Springer, 2008, pp. 607-622. DOI: 10.1007/978-3-540-74496-2\_36
				
				\bibitem{multistream} 2015, P. L'Ecuyer,  ``Random number generation with multiple streams for sequential and parallel computing''. WSC '15: Proceedings of the 2015 Winter Simulation Conference, December 2015, pp. 31–44
				
				\bibitem{intel} 2023, ``Intel® 64 and IA-32 Architectures, Optimization Reference Manual''
				
				\begin{comment}
				@proceedings{10.5555/2888619,
				title = {WSC '15: Proceedings of the 2015 Winter Simulation Conference},
				year = {2015},
				isbn = {9781467397414},
				publisher = {IEEE Press},
				location = {Huntington Beach, California}
				}
				\end{comment}
				
			\end{thebibliography}
			
		\end{document}
